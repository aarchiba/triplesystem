# Code version 1

This code may never be imported to the project as-is. But at the least it is necessary to document how to use it, which largely means describing relevant notebooks.

## Generating the equations of motion

The notebook `n-ppn` contains a discussion of the problem and uses sympy to construct the Lagrangian and take appropriate derivatives of it to extract the equations of motion. These require some special handling to keep the equations even marginally manageable: I introduce symbols for the distances between bodies and squared velocities, for example. And of course I work in units where c is 1; G does not appear because rather than using the masses to parameterize the Lagrangian I use coefficients that appear in the Nordtvedt paper, that only equal products of the masses in GR. This notebook also contains some terms for tidal effects on the inner white dwarf. Some of the complexities here are to work around limitations in (past versions of) sympy (most notably it crashed the common subexpression elimination code). Should be revisited with care.

The notebook `k-lagrangian-rhs` is a partial cleanup of the above, with the intention of generating an RHS that supports the computation of derivatives with respect to initial conditions and parameters. It is as yet incomplete, partly because generating workable C++ code from these very complicated expressions is nontrivial, and partly because it is necessary to choose a sensible, small set of parameters.

Note that the generated code is a templated C++ file that can be compiled with either long double or quad precision numeric types. Unfortunately Boost's quad precision type uses templates to pre-evaluate expressions at compile time, but the expressions in the generated C++ file are so awful the compiler uses all memory on the machine and then crashes. So there's an adapter layer that makes sure this only gets fed native `__quad128`.

The differential equation that gets solved uses as its variables: positions, velocities, and masses of the three objects, plus elapsed proper time delay. This last is computed by integrating the time dilation minus one. The masses of course never change during integration, but it was easier to put them into the state vector than supply them as parameters; the cost of doing things this way is probably moderate.

## Importing a new data set

To use a new collection of TOAs, it is necessary to assign them pulse numbers. One must then find a starting parameter set, then run an initial minimization with MINUIT. Getting an actually good best-fit set of values requires iterating between MINUIT minimization and MCMC runs; MINUIT is much faster at approaching the minimum but when it gets hung up on round-off error MCMC will often find a better solution. Be warned also that it can take a long time for MCMC to "notice" the SEP-violating solution.

## The fitting process

When a Fitter object is created, it is provided with a collection of information, the "problem specification": input files, par file to get the astrometry, choices of what to fit for and whether to restrict to GR, et cetera. The code maintains a database listing the best set of parameters known for each problem specification. A new data set will obviously not have any such parameter set defined, and starting from an approximately-right one dramatically speeds up the fitting process.

* `n-fitting.ipynb` - use MINUIT to optimize the fit. This is probably the easiest place to set up a problem specification; it is written out to fitter.pickle, and various other notebooks use this problem specification by default. (Note that problem specifications are just dictionaries of keyword arguments to pass to Fitter, so they can be inspected and modified as needed.) Actual fitting will take forever starting from a random set of values, so it's best to use the function below before actually starting the fitting. You may also want to restart the minimization from a best-fit value out of the MCMC code, if a better one comes up than the working values out of this notebook. Note that MINUIT prints all sorts of output to the console, if you want to track the (slow) optimization process. Expect this to take a few hours.
* `b-best-parameters.ipynb` - use this to update the database of best parameter sets. It offers three options: try the best-fit values for all known problem specifications, try the best value seen by the optimizer so far, or try the best value seen by the MCMC so far. In each case the values are actually *tried* before incorporating them, so it is safe to do this even if there have been code or TOA changes.
* `emcee_chain_mpi.py` and `submit_emcee_mpi.sh` - PBS jobs to run the emcee calculations. It uses the fitter parameters in emcee_params.pickle. It also requires a collection of "walkers", parameter sets distributed according to the error ellipse (specifically as offsets from the initial minimum estimate). The emcee run will move these to the right error ellipse, but the closer they are the faster emcee convergence will be. If these are the wrong dimension, the run will fail; you can use n-emcee-output to pull reasonable values from a previous run.
* `n-emcee-output` - summarizes results from an in-progress or finished run of emcee_chain_mpi.py. This shows a number of plots useful for diagnosing progress, and generates a number of summary files. These files can be useful for starting another emcee run for similar parameters. Some of the summary files are also used by other notebooks for computing final publishable results.

## Differential equation solving

* `quad_integrate.pyx` - this Cython module provides the python-facing interface to the differential equation integrator. It supports both long double and quad precision internally, but communicates to python only through long doubles, since numpy has no quad precision support. This is not just a generic differential equation solver; it supports root-finding and implements Shapiro plus Roemer delays so that it can compute the pulse emission time for a given barycentered arrival time. It can also only run forward. Different sets of physics are set by changing the parameters it is handed upon construction. 
* `extra.hpp`, `odeint_header.hpp` - various support functions, not all still needed, to connect Cython to Boost. 
* `setup.py` - currently a quick hack to allow building of the Cython extension; use `python setup.py build_ext --inplace`. 
